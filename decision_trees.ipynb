{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [  # first two columns being features and last one being response\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]\n",
    "header = ['color', 'diameter', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Green', 'Red', 'Yellow'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for row in data:\n",
    "    labels.append(row[0])\n",
    "unique_labels = set(labels)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "impurity: chance of being incorrect if randomly assign a label to an example in the same set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What questions to ask?\n",
    "* When to ask question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a list of questions, we'll iterate over every value for every feature in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, column, value):\n",
    "        self.column = column  # column no (0 for color)\n",
    "        self.value = value  # column value (e.g. Green)\n",
    "        \n",
    "    def match(self, example):\n",
    "        \"\"\"Compare feature value in Question to feature value in example\"\"\"\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"Print Question\"\"\"\n",
    "        condition = '=='\n",
    "        if is_numeric(self.value):\n",
    "            condition = '>='\n",
    "        return 'Is ' + str(header[self.column]) + str(condition) + str(self.value) + '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows, question):\n",
    "    \"\"\"For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\"\"\"\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best question is the one which reduces the uncertainity the most. Gini impurity quantifies how much uncertainity is at a node. Information gain quantifies how much a question reduces the uncertainity. Entropy is a probalistic measure of uncertainity.\n",
    "* Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset\n",
    "* Information gain (measure of reduction in uncertainity) is used to decide which feature to split on at each step in building the tree. Simplicity is best, so we want to keep our tree small. To do so, at each step we should choose the split that results in the purest daughter nodes.\n",
    "\n",
    "To compute Gini impurity for a set of items with $J$ classes, suppose $i \\in { 1 , 2 , . . . , J }$, and let $p_i$ be the fraction of items labeled with class $i$ in the set:  \n",
    "[Gini impurity](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) = $\\sum($P(item with label $i$) * P(mistake in  categorizing that label $i$)$)$\n",
    "$$I_G = 1 - \\sum_{i=1}^J p_i^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    \"\"\"Counts number of each type of example in the dataset\"\"\"\n",
    "    counts = {}\n",
    "    for row in rows:\n",
    "        label = row[-1]  # last column\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    \"\"\"Calculate Gini impurity for list of rows\"\"\"\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for label in counts:\n",
    "        prob_label = counts[label] / float(len(rows))\n",
    "        impurity -= prob_label ** 2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainity):\n",
    "    \"\"\"Information gain: the uncertainty of the starting node, minus the 'weighted' (average) impurity of\n",
    "    two child nodes.\"\"\"\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainity - p*gini(left) - (1 - p)*gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "    and calculating the information gain.\"\"\"\n",
    "    best_gain = 0  # keep track of information gain\n",
    "    best_question = None  # keep track of feature/value that produced it\n",
    "    current_uncertainity = gini(rows)\n",
    "    n_features = len(rows[0]) - 1  # no of columns\n",
    "    \n",
    "    for col in range(n_features):  # for each feature\n",
    "        values = set([row[col] for row in rows])  # unique values in column\n",
    "        \n",
    "        for val in values:\n",
    "            question = Question(col, val)\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "            if len(true_rows)  == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainity)\n",
    "            if gain >= best_gain:\n",
    "                best_gain = gain\n",
    "                best_question = question\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"A leaf node classifies data\"\"\"\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)\n",
    "\n",
    "class DecisionNode:\n",
    "    \"\"\"A decision node asks a question\"\"\"\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    \n",
    "    # artitioing the dataset on each of the unique attribute, calculate the information gain,\n",
    "    # and return the question that produces the highest gain.\n",
    "    info, question = find_best_split(rows)\n",
    "    \n",
    "    # base case (no information gain)\n",
    "    if info == 0:\n",
    "        return Leaf(rows)\n",
    "    \n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    \n",
    "    # recursive call to build true_branch and false_branch\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    \n",
    "    # Return a Question node, which records the best feature / value to ask at this point\n",
    "    return DecisionNode(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=''):\n",
    "    \n",
    "    # base case (leaf)\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + 'Predict' + str(node.predictions))\n",
    "        return\n",
    "    \n",
    "    # print question at this node\n",
    "    print(spacing + str(node.question))\n",
    "    \n",
    "    # recursively print questions\n",
    "    print(spacing + '---> True:')\n",
    "    print_tree(node.true_branch, spacing + '\\t')\n",
    "    print(spacing + '---> False:')\n",
    "    print_tree(node.false_branch, spacing + '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is diameter>=3?\n",
      "---> True:\n",
      "\tIs color==Yellow?\n",
      "\t---> True:\n",
      "\t\tPredict{'Apple': 1, 'Lemon': 1}\n",
      "\t---> False:\n",
      "\t\tPredict{'Apple': 1}\n",
      "---> False:\n",
      "\tPredict{'Grape': 2}\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(data)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    \n",
    "    # base case\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "    \n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node to the example we're considering.\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(counts):\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for label in counts.keys():\n",
    "        probs[label] = str(int(counts[label] / total * 100)) + '%'\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': '50%', 'Lemon': '50%'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_leaf(classify(data[1], tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 4, 'Apple'],\n",
    "    ['Red', 2, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Apple \t Predicted: {'Apple': '100%'}\n",
      "Actual: Apple \t Predicted: {'Apple': '50%', 'Lemon': '50%'}\n",
      "Actual: Grape \t Predicted: {'Grape': '100%'}\n",
      "Actual: Grape \t Predicted: {'Grape': '100%'}\n",
      "Actual: Lemon \t Predicted: {'Apple': '50%', 'Lemon': '50%'}\n"
     ]
    }
   ],
   "source": [
    "for row in test:\n",
    "    print('Actual: {} \\t Predicted: {}'.format(row[-1], print_leaf(classify(row, tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
